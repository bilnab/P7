{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0d221a-55f3-4e42-bfa1-d72cf8ddf0d3",
   "metadata": {},
   "source": [
    "## 1- test distilbert préentrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80973edb-f732-4d6c-8467-9cf056a11ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") #“distilbert-base-uncased-finetuned-sst-2-english\n",
    "results=classifier(\"we love you\")\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "results=classifier(\"we love you\")\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c0db1-e60d-415b-9ae3-72c191cda157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "results=classifier(\"we love you\")\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a63378-42d4-454f-aa56-0a54d482f932",
   "metadata": {},
   "source": [
    "## 2-test distilbert préentrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201c6329-e29d-4653-ac76-1faf2612ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'activation_13', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_57', 'classifier', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: LABEL_0, with score: 0.5104\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "#This model only exists in PyTorch, so we use the _from_pt_ flag to import that model in TensorFlow\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)#, from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "results=classifier(\"we love you\")\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51ec01-e240-47a2-8e7a-f83e5b94e5d8",
   "metadata": {},
   "source": [
    "## 3-sauvegarde du modèle en local sans le pusher dans le hub de huggingfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011ce515-c24b-45c8-9c09-ab7a19a22e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./test/tokenizer_config.json',\n",
       " './test/special_tokens_map.json',\n",
       " './test/vocab.txt',\n",
       " './test/added_tokens.json',\n",
       " './test/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save en local\n",
    "model.save_pretrained('./test/', push_to_hub=False)\n",
    "tokenizer.save_pretrained('./test/', push_to_hub=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c83eb-efff-4e19-b512-136576632674",
   "metadata": {},
   "source": [
    "## 4- relecture du modèle à partir du repertoire local -> ca fonctionne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc45364-c7c1-41fc-b7fd-56021bd69ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./test were not used when initializing TFDistilBertForSequenceClassification: ['dropout_57']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./test and are newly initialized: ['dropout_77']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: LABEL_0, with score: 0.5104\n"
     ]
    }
   ],
   "source": [
    "#reload en local (attention )\n",
    "model2=TFAutoModelForSequenceClassification.from_pretrained('./test')\n",
    "tokenizer2 = AutoTokenizer.from_pretrained('./test')\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model2, tokenizer=tokenizer2)\n",
    "results=classifier(\"we love you\")\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7d7f0-d7ff-4d8b-a9f9-459511b6db0f",
   "metadata": {},
   "source": [
    "## 5- connexion au workspace azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abfaad1-cb70-43c2-9982-0a8215719dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with nab-ML\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36042a47-bfcd-4ca3-ac7c-29041a129d15",
   "metadata": {},
   "source": [
    "## 6-azure model registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112edf01-9040-484a-9dc8-8d75e895e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model distilbert-sentiment\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "classification_model = Model.register(workspace=ws,\n",
    "                       model_name='distilbert-sentiment',\n",
    "                       model_path='./test',# local path\n",
    "                       description='A text classification model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86f5bd-61bd-492e-8e53-acd001f3c87d",
   "metadata": {},
   "source": [
    "## 7-lecture des modèles registrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214838f8-87aa-47b7-a47f-e512790525f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-sentiment version: 1\n",
      "\n",
      "\n",
      "sentiment_model_weight version: 1\n",
      "\n",
      "\n",
      "sentiment_model version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lecture des modèles\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf546d-954e-48e9-8720-49c97f72bb86",
   "metadata": {},
   "source": [
    "## 8-Creation du  folder pour deploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce36327-d800-473f-9ee1-56eb1c092353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sentiment_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './sentiment_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_sentiment.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e902aa-bdde-469b-aa80-868b30f16901",
   "metadata": {},
   "source": [
    "## 9-ecriture du scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231e2d12-c881-464e-8ef3-84d5890b7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sentiment_service\\score_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "import json\n",
    "from azureml.core import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model weight and load it\n",
    "    #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'distilbert-sentiment')\n",
    "    model_path = Model.get_model_path('distilbert-sentiment')\n",
    "    \n",
    "    model2=TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = pipeline(\"sentiment-analysis\", model=model2, tokenizer=tokenizer2)\n",
    "    \n",
    "\n",
    "# Called when a request is received\n",
    "def run(text):\n",
    "    return model(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31790419-3bf6-4132-8e59-55dcaed14641",
   "metadata": {},
   "source": [
    "## 10- definition de l'environnement\n",
    "* on recupere un environnement d'entrainement avec les bonnes dependances\n",
    "* on ajoute la ligne de paramétrage d'inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d50e8e-d682-4048-953a-fac0972b7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "# Configure the scoring environment\n",
    "#service_env = Environment.get(workspace=ws, name=\"customize_curated\")\n",
    "service_env = Environment.get(workspace=ws, name=\"customize_curated\")\n",
    "service_env.inferencing_stack_version = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754efad3-a895-4756-9d20-2a67bace74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967550d-cc68-4b3c-9970-d0a91d40f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import CondaDependencies\n",
    "#service_env = Environment(name='service-env')\n",
    "#python_packages = ['transformers','os']\n",
    "#,'pandas','string','os','azureml-defaults', 'azure-ml-api-sdk']\n",
    "#conda_dep = CondaDependencies()\n",
    "#for package in python_packages:\n",
    " #   service_env.python.conda_dependencies.add_pip_package(package)\n",
    "#service_env.python.conda_dependencies=conda_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bde983-e21d-4392-9af5-ca3aa3aa848b",
   "metadata": {},
   "source": [
    "## 11- inference config et deploiement ok pour le distilbert préentrainé non finetuné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634feabf-3f49-4baa-9a19-4985f29796dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-02-26 13:29:27+01:00 Creating Container Registry if not exists.\n",
      "2022-02-26 13:29:27+01:00 Registering the environment.\n",
      "2022-02-26 13:29:29+01:00 Use the existing image.\n",
      "2022-02-26 13:29:29+01:00 Generating deployment configuration.\n",
      "2022-02-26 13:29:31+01:00 Submitting deployment to compute.\n",
      "2022-02-26 13:29:35+01:00 Checking the status of deployment distilbert-sentiment..\n",
      "2022-02-26 13:37:44+01:00 Checking the status of inference endpoint distilbert-sentiment.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "model = ws.models['distilbert-sentiment']\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"distilbert-sentiment\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7560ca-2c64-4c8d-a12e-d40827a44ce7",
   "metadata": {},
   "source": [
    "## 12- test du deploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e514fc3c-63c9-4a97-9d74-5ab3ef4475d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.510405957698822}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Call the web service\n",
    "service.run(\"we love you\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2d4d7b-1f7a-4fb0-9bd5-4bc7a356b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345d833-57d4-4d3b-8ea4-f0acaf2df38f",
   "metadata": {},
   "source": [
    "## 13- rechargement du modele distilbert pre entraine avec les poids finetunés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4753269e-a253-4386-ae39-e139866881d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1bde4c769d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "trained_model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2)\n",
    "    #compilation correpondant à l'entrainement\n",
    "trained_model.compile(loss=loss,optimizer=optimizer, metrics=[metric])\n",
    "    #chargement des poids del'entrainement\n",
    "trained_model.load_weights('./bert/mod_distil_sent_sw_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938f276-8414-424f-8cce-75c7febe6174",
   "metadata": {},
   "source": [
    "## 14- sauvegarde en local du modele finetuné pour deploiement\n",
    "* il suffit de remplacer le modele path du model registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8363bd5c-45b1-4b59-b031-5424bccb9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer.save_pretrained('./test2/', push_to_hub=False)\n",
    "trained_model.save_pretrained('./test2/', push_to_hub=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75436ef4-3dce-4bd2-9ab4-8bfd20b927db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = pipeline(\"sentiment-analysis\", model=trained_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81c68033-1306-4ca0-b378-cf4dba628727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8176223039627075}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(\"we love you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bfb48c-751c-49bf-ba08-d360b9ac4cf2",
   "metadata": {},
   "source": [
    "## 15- registration du modèle fine tuné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a265aae7-a8b3-4918-91b4-558e5a251123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model distilbert-sentiment-ft\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "classification_model = Model.register(workspace=ws,\n",
    "                       model_name='distilbert-sentiment-ft',\n",
    "                       model_path='./test2',# local path\n",
    "                       description='A text classification model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1f546-73f3-4c8d-9418-bd5480a7e69e",
   "metadata": {},
   "source": [
    "## 15- scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bde8391-1d49-4c8b-86df-ad7fe4661f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sentiment_service_ft folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './sentiment_service_ft'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_sentiment.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "910d3701-4686-4d87-a0ad-bbc788f91949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./sentiment_service_ft\\score_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "import json\n",
    "from azureml.core import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model weight and load it\n",
    "    #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'distilbert-sentiment')\n",
    "    model_path = Model.get_model_path('distilbert-sentiment-ft')\n",
    "    \n",
    "    model2=TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = pipeline(\"sentiment-analysis\", model=model2, tokenizer=tokenizer2)\n",
    "    \n",
    "\n",
    "# Called when a request is received\n",
    "def run(text):\n",
    "    return model(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc4d2f7-2551-4475-882a-ddce5306945f",
   "metadata": {},
   "source": [
    "## 16- deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961b571-d081-426e-8b65-c707e967c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "# Configure the scoring environment\n",
    "#service_env = Environment.get(workspace=ws, name=\"customize_curated\")\n",
    "service_env = Environment.get(workspace=ws, name=\"customize_curated\")\n",
    "service_env.inferencing_stack_version = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02f65ac5-7798-49d1-81b8-ac85c5c85afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-02-26 15:44:22+01:00 Creating Container Registry if not exists.\n",
      "2022-02-26 15:44:22+01:00 Registering the environment.\n",
      "2022-02-26 15:44:24+01:00 Use the existing image.\n",
      "2022-02-26 15:44:25+01:00 Generating deployment configuration.\n",
      "2022-02-26 15:44:26+01:00 Submitting deployment to compute.\n",
      "2022-02-26 15:44:31+01:00 Checking the status of deployment distilbert-sentiment-ft..\n",
      "2022-02-26 15:52:16+01:00 Checking the status of inference endpoint distilbert-sentiment-ft.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "model = ws.models['distilbert-sentiment-ft']\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"distilbert-sentiment-ft\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84504b50-efc7-47f2-9d4b-57d3429c862f",
   "metadata": {},
   "source": [
    "## 17- test du deploiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4998666a-f0f8-4cb3-87f4-eede88b06d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8176222443580627}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the web service\n",
    "service.run(\"we love you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
